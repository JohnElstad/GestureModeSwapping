This is the code for my capstone project to train a neural network that can recognize different gestures. The project uses Mediapipe's libraries to recognized a users hand and then uses a trained network to take the hand predictions and recognize different gestures.

4/13/22
Currently, this code works on my laptop, but needs mediapipe and tensorflow installed. There are three jupyter notebooks. One for collecting data with the hand tracking, one for training the model and one for testing the trained model on a new video stream.
