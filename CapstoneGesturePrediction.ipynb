{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed5393cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from mediapipe) (3.14.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from mediapipe) (4.5.5.64)\n",
      "Requirement already satisfied: numpy in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from mediapipe) (1.21.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from mediapipe) (3.5.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from mediapipe) (0.15.0)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from protobuf>=3.11.4->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->mediapipe) (1.4.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->mediapipe) (9.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->mediapipe) (4.31.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->mediapipe) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00f3dd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd892ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeec70ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import hands model from mediapipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ed4962f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X', 'Y', 'Z']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list('XYZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd59bbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X  Y  Z  Label\n",
       "0  1  2  3      0\n",
       "1  3  4  5      0\n",
       "2  1  2  3      0\n",
       "3  3  4  5      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame([[1, 2,3,0], [3, 4,5,0]], columns=['X','Y','Z','Label'])\n",
    "df2 = pd.DataFrame([[1, 2,3,0], [3, 4,5,0]], columns=['X','Y','Z','Label'])\n",
    "df3 = pd.concat([df, df2], ignore_index = True)\n",
    "df3.reset_index()\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a40ab7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.6.* in c:\\users\\johne\\anaconda3\\envs\\tf\\lib\\site-packages (2.6.0)\n"
     ]
    }
   ],
   "source": [
    "finishedData = []\n",
    "!pip install keras==2.6.*\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "159fe33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('CapstoneAgModelV2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad06ea2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 63)]              0         \n",
      "_________________________________________________________________\n",
      "d1 (Dense)                   (None, 63)                4032      \n",
      "_________________________________________________________________\n",
      "d2 (Dense)                   (None, 126)               8064      \n",
      "_________________________________________________________________\n",
      "d3 (Dense)                   (None, 252)               32004     \n",
      "_________________________________________________________________\n",
      "d5 (Dropout)                 (None, 252)               0         \n",
      "_________________________________________________________________\n",
      "d4 (Dense)                   (None, 126)               31878     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 381       \n",
      "_________________________________________________________________\n",
      "s1 (Activation)              (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 76,359\n",
      "Trainable params: 76,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a3fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5,max_num_hands = 1) as hands:     \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    frameWidth = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    frameHeight = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    while cap.isOpened():\n",
    "        ret,frame =cap.read()\n",
    "        \n",
    "        #detections\n",
    "        image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.flip(image,1)\n",
    "            \n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        gestureSelection = 0; #0 = no gestures selected, 1 = Hands Up, 2 = Thumbs Up\n",
    "        flat_list = []\n",
    "        if results.multi_hand_landmarks:\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS, \n",
    "                                        mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                        mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),\n",
    "                                         )\n",
    "                coordinateList = []  \n",
    "                for count,landmark in enumerate(hand.landmark):\n",
    "                    \n",
    "                    x = landmark.x\n",
    "                    y = landmark.y\n",
    "                    z = landmark.z\n",
    "                    coordinates = [x,y,z]\n",
    "                    coordinateList.append(coordinates)\n",
    "                    \n",
    "                flat_list = list(np.concatenate(coordinateList).flat)\n",
    "                confidence = np.max(model.predict(np.array(flat_list).reshape(1,-1)))\n",
    "                prediction = np.argmax(model.predict(np.array(flat_list).reshape(1,-1)))\n",
    "                if prediction == 0:\n",
    "                    outputText = 'Nothing'\n",
    "                elif prediction == 1:\n",
    "                    outputText = 'Stop'\n",
    "                elif prediction == 2:\n",
    "                    outputText = 'Go forward'\n",
    "                    \n",
    "                image = cv2.putText(image, str(outputText), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       2, [255,0,0], 2, cv2.LINE_AA)\n",
    "                image = cv2.putText(image, str(confidence), (50, 400), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       1, [0,255,0], 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "#                     print(f\"X={x}\")\n",
    "#                     print(f\"Y={y}\")\n",
    "#                     print(f\"Y={y}\")\n",
    "#                     image = cv2.circle(image, [int(x*frameWidth),int(y*frameHeight)], 15, [0,0,255], 5)\n",
    "                \n",
    "        cv2.imshow('Hand Tracking',image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4400bb1",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52daf47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
